{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18120,
     "status": "ok",
     "timestamp": 1757102008882,
     "user": {
      "displayName": "Crazy G",
      "userId": "16220097015500207603"
     },
     "user_tz": 240
    },
    "id": "9jedYTGOcBuj",
    "outputId": "716550f9-3cd7-4586-b14a-9103e64fe191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive on colab only\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1757102091637,
     "user": {
      "displayName": "Crazy G",
      "userId": "16220097015500207603"
     },
     "user_tz": 240
    },
    "id": "nFQ1JGiqcPB0"
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ğŸ“ Seed Titles\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SEED_TITLES = [\n",
    "    # Programming & AI\n",
    "    \"Python_(programming_language)\",\n",
    "    \"JavaScript\",\n",
    "    \"Artificial_intelligence\",\n",
    "    \"Machine_learning\",\n",
    "    \"Natural_language_processing\",\n",
    "    \"Transformer_(machine_learning_model)\",\n",
    "    \"Git\",\n",
    "    \"HTML\",\n",
    "    \"CSS\",\n",
    "    \"Neural_network\",\n",
    "    \"Computer_vision\",\n",
    "    \"Data_structure\",\n",
    "    \"Algorithm\",\n",
    "    \"Recursion_(computer_science)\",\n",
    "    \"Big_O_notation\",\n",
    "\n",
    "    # Mythology & Lore\n",
    "    \"Sun_Wukong\",\n",
    "    \"Journey_to_the_West\",\n",
    "    \"Chinese_mythology\",\n",
    "    \"Greek_mythology\",\n",
    "    \"Norse_mythology\",\n",
    "    \"Magic_(paranormal)\",\n",
    "    \"Wand\",\n",
    "    \"Alchemy\",\n",
    "    \"Divination\",\n",
    "    \"Horcrux\",\n",
    "    \"Hogwarts\",\n",
    "    \"Wizard\",\n",
    "    \"Spell_(paranormal)\",\n",
    "    \"Mythology\",\n",
    "\n",
    "    # Literature & Style\n",
    "    \"William_Shakespeare\",\n",
    "    \"Shakespearean_language\",\n",
    "    \"Poetry\",\n",
    "    \"Sonnet\",\n",
    "    \"Fantasy_literature\",\n",
    "    \"Harry_Potter\",\n",
    "    \"J._K._Rowling\",\n",
    "    \"Literary_style\",\n",
    "    \"Dialogue\",\n",
    "    \"Narrative\",\n",
    "    \"Character_(arts)\",\n",
    "    \"Plot_(narrative)\",\n",
    "    \"Symbolism\",\n",
    "\n",
    "    # Philosophy & Expression\n",
    "    \"Consciousness\",\n",
    "    \"Creativity\",\n",
    "    \"Emotion\",\n",
    "    \"Language\",\n",
    "    \"Semiotics\",\n",
    "    \"Provenance\",\n",
    "    \"Modularity\",\n",
    "    \"Expressive_writing\",\n",
    "    \"Storytelling\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80663,
     "status": "ok",
     "timestamp": 1757107166498,
     "user": {
      "displayName": "Crazy G",
      "userId": "16220097015500207603"
     },
     "user_tz": 240
    },
    "id": "p3rNwcYkb5SL",
    "outputId": "9b665965-0632-42bd-9b0f-66f0ecec89e7"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ğŸ“ Config\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MAX_ARTICLES = 100\n",
    "#SAVE_DIR = Path(\"/content/drive/MyDrive/dataset/wiki_crawl\") #google colab path\n",
    "SAVE_DIR = Path(\"./dataset/wiki_crawl\") #local path\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"WEB-Crawler/1.0 (https://crazyg.is-a.dev or crazygiscool@proton.me)\"\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ğŸ”§ Fetch Article Content via MediaWiki API\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def fetch_article(title):\n",
    "    url = \"https://en.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "        \"titles\": title,\n",
    "        \"format\": \"json\",\n",
    "        \"redirects\": 1\n",
    "    }\n",
    "    response = requests.get(url, params=params, headers=HEADERS)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"HTTP error {response.status_code}\")\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Invalid JSON response: {e}\")\n",
    "    if \"query\" not in data or \"pages\" not in data[\"query\"]:\n",
    "        raise ValueError(\"Malformed response structure\")\n",
    "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
    "    return page.get(\"title\"), page.get(\"extract\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ğŸ§  Format Content with Markdown and Glyphs\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def formatter(title, content):\n",
    "    glyph = infer_glyph(title)\n",
    "    lines = content.strip().split('\\n')\n",
    "    formatted = [f\"<<glyph:{glyph}>>\", f\"# {title.replace('_', ' ')}\", \"\"]\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # Add section headers for long paragraphs\n",
    "        if len(line.split()) > 12:\n",
    "            formatted.append(f\"## {line}\")\n",
    "        else:\n",
    "            formatted.append(f\"> {line}\")\n",
    "\n",
    "    return '\\n'.join(formatted)\n",
    "\n",
    "def infer_glyph(title):\n",
    "    title = title.lower()\n",
    "    if \"python\" in title or \"html\" in title or \"css\" in title or \"javascript\" in title:\n",
    "        return \"code\"\n",
    "    if \"ai\" in title or \"machine\" in title or \"neural\" in title or \"transformer\" in title:\n",
    "        return \"ai\"\n",
    "    if \"sun wukong\" in title or \"journey\" in title or \"myth\" in title:\n",
    "        return \"myth\"\n",
    "    if \"shakespeare\" in title or \"poetry\" in title or \"sonnet\" in title:\n",
    "        return \"literature\"\n",
    "    if \"harry potter\" in title or \"wand\" in title or \"hogwarts\" in title:\n",
    "        return \"magic\"\n",
    "    return \"info\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ğŸ” Safe Fetch with Retry\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def safe_fetch(title, retries=3, delay=2):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return fetch_article(title)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Attempt {attempt+1} failed for {title}: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return title, None\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ğŸ” Crawl from Seed Titles\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def crawl_wikipedia(seed_titles, max_articles):\n",
    "    visited = set()\n",
    "    queue = list(seed_titles)\n",
    "\n",
    "    while queue and len(visited) < max_articles:\n",
    "        title = queue.pop(0)\n",
    "        if title in visited:\n",
    "            continue\n",
    "\n",
    "        page_title, content = safe_fetch(title)\n",
    "        if content:\n",
    "            formatted = formatter(page_title, content)\n",
    "            filename = SAVE_DIR / f\"{page_title.replace(' ', '_')}.md\"\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(formatted)\n",
    "            print(f\"âœ… Saved: {page_title}\")\n",
    "            visited.add(title)\n",
    "        else:\n",
    "            print(f\"âŒ Skipped: {title} (no content)\")\n",
    "\n",
    "        time.sleep(1.5)  # Respectful crawling\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ğŸš€ Run Crawler\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "crawl_wikipedia(SEED_TITLES, MAX_ARTICLES)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMKmKHKcoAzu4piIOKvklab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
